import streamlit as st
import pandas as pd
from pdfminer.high_level import extract_text
from datetime import datetime
import pytz
import os
import requests

def app():
    st.title("ä¸€æ‹¬ã§ã‚µã‚¹ãƒ†ãƒŠå˜èªã‚’ã‚«ã‚¦ãƒ³ãƒˆ")
    # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã§ã®urlsã®åˆæœŸåŒ–
    if 'urls' not in st.session_state:
        st.session_state.urls = []

    # ã‚¹ã‚¯ãƒªãƒ—ãƒˆã®ã‚ã‚‹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®çµ¶å¯¾ãƒ‘ã‚¹ã‚’å–å¾—
    dir_path = os.path.dirname(os.path.realpath(__file__))
    parent_dir = os.path.dirname(dir_path)
    default_csv_path = os.path.join(parent_dir, 'kw-hierarchy_20240326.csv')

    st.subheader('ğŸ€Step1. åˆ†é¡1~4å˜èªãƒ»å€ç‡ãƒ»æ®µéšè¨­å®š')

    # CSVé¸æŠã‚ªãƒ—ã‚·ãƒ§ãƒ³ã‚’ãƒ—ãƒ«ãƒ€ã‚¦ãƒ³ã‹ã‚‰é¸æŠ
    csv_option = st.selectbox("CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„:",
                                options=["", 'ã€Œkw-hierarchy_20240326.csvã€ã‚’åˆ©ç”¨ã™ã‚‹', 'åˆ†é¡1~4ã‚’æ•´ç†ã—ãŸæ–°è¦CSVã‚’åˆ©ç”¨ã™ã‚‹'],
                                index=0,
                                format_func=lambda x: x if x else "é¸æŠã—ã¦ãã ã•ã„...")

    # ã€Œkw-hierarchy_20240326.csvã€ã‚’åˆ©ç”¨ã™ã‚‹é¸æŠè‚¢ãŒé¸ã°ã‚ŒãŸå ´åˆ
    if csv_option == 'ã€Œkw-hierarchy_20240326.csvã€ã‚’åˆ©ç”¨ã™ã‚‹':
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆCSVã®èª­ã¿è¾¼ã¿
        load_default_csv(default_csv_path)
        proceed_to_step2()
    
    # æ–°è¦CSVã‚’åˆ©ç”¨ã™ã‚‹é¸æŠè‚¢ãŒé¸ã°ã‚ŒãŸå ´åˆ
    elif csv_option == 'åˆ†é¡1~4ã‚’æ•´ç†ã—ãŸæ–°è¦CSVã‚’åˆ©ç”¨ã™ã‚‹':
        upload_new_csv()

def load_default_csv(default_csv_path):
    if 'df' not in st.session_state or 'uploaded_file_info' not in st.session_state:
        st.session_state.df = pd.read_csv(default_csv_path)
        st.session_state.uploaded_file_info = 'ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆCSVãŒèª­ã¿è¾¼ã¾ã‚Œã¾ã—ãŸ'

def upload_new_csv():
    # CSVãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ä¾‹ã‚’è¡¨ç¤º
    example_data = {
        "åˆ†é¡1": ["ä¾¡å€¤å‰µé€ ãƒ¢ãƒ‡ãƒ«", "ä¾¡å€¤å‰µé€ ãƒ¢ãƒ‡ãƒ«"],
        "åˆ†é¡2": ["ä¾¡å€¤å‰µé€ ãƒ¢ãƒ‡ãƒ«", "ä¾¡å€¤å‰µé€ ãƒ¢ãƒ‡ãƒ«"],
        "åˆ†é¡3": ["ä¾¡å€¤å‰µé€ ãƒ¢ãƒ‡ãƒ«", "ä¾¡å€¤å‰µé€ ãƒ¢ãƒ‡ãƒ«"],
        "åˆ†é¡4": ["ä¾¡å€¤å‰µé€ ", "ä¾¡å€¤å‰µé€ ã‚¹ãƒˆãƒ¼ãƒªãƒ¼"]
    }
    example_df = pd.DataFrame(example_data)
    st.markdown("ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹CSVã®ä¾‹:")
    st.dataframe(example_df)
    st.text("... (ã“ã®ä¸‹ã«ã‚‚è¡ŒãŒç¶šã)")
    st.text("")
    uploaded_csv = st.file_uploader("åˆ†é¡1~4ã®ã‚µã‚¹ãƒ†ãƒŠå˜èªã‚’æ•´ç†ã—ãŸCSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„", type=["csv"])
    if uploaded_csv is not None:
        st.success('æ–°è¦CSVã®èª­ã¿è¾¼ã¿ã«æˆåŠŸã—ã¾ã—ãŸï¼Step2ã«é€²ã¿ã¾ã™')
        st.session_state.df = pd.read_csv(uploaded_csv)
        st.session_state.df.columns = st.session_state.df.columns.str.strip()
        st.session_state.uploaded_file_info = uploaded_csv.name + ' ãŒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¾ã—ãŸ'
        proceed_to_step2()

def proceed_to_step2():
    # ãƒ•ã‚¡ã‚¤ãƒ«ã‚¿ã‚¤ãƒ—ã®é¸æŠ
    st.sidebar.divider()
    st.sidebar.markdown("### :orange[ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¿ã‚¤ãƒ—é¸æŠ]")  # ã‚µã‚¤ãƒ‰ãƒãƒ¼ã«åˆ†é¡ã®é¸æŠã‚’è¿½åŠ 
    file_type = st.sidebar.radio("ä»Šå›ã®è©•ä¾¡å¯¾è±¡ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚¿ã‚¤ãƒ—ã‚’é¸æŠã—ã¦ãã ã•ã„ï¼š", ("PDF", "Webãƒªãƒ³ã‚¯"))
    st.session_state.file_type = file_type  # ãƒ•ã‚¡ã‚¤ãƒ«ã‚¿ã‚¤ãƒ—ã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã«ä¿å­˜

    # ãƒ•ã‚¡ã‚¤ãƒ«ã‚¿ã‚¤ãƒ—ã«å¿œã˜ãŸå‡¦ç†ã®å®Ÿè¡Œ
    if st.session_state.file_type == "PDF":
        process_pdf(st.session_state.df)
    elif st.session_state.file_type == "Webãƒªãƒ³ã‚¯":
        process_urls(st.session_state.df)

def update_file_type():
    # ãƒ•ã‚¡ã‚¤ãƒ«ã‚¿ã‚¤ãƒ—ã®å¤‰æ›´ã‚’æ¤œçŸ¥ã™ã‚‹ãŸã‚ã®ãƒ€ãƒŸãƒ¼é–¢æ•°ï¼ˆå¿…è¦ã«å¿œã˜ã¦å®Ÿè£…ï¼‰
    pass

def process_file_type(df, file_type):
    if file_type == "PDF":
        process_pdf(df)
    else:
        process_urls(df)

def process_pdf(df):
    st.divider()
    st.subheader('ğŸ€Step2. è©•ä¾¡å¯¾è±¡ã®è¨­å®š')
    uploaded_file = st.file_uploader("ä»Šå›ã®è©•ä¾¡å¯¾è±¡ã®PDFãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„", type=["pdf"])
    if uploaded_file is not None:
        text = extract_text(uploaded_file)
        uploaded_file_name = uploaded_file.name
        # uploaded_fileã‚’å¼•æ•°ã¨ã—ã¦æ¸¡ã™
        your_pdf_processing_function(df, uploaded_file, text, uploaded_file_name)

def process_urls(df):
    st.divider()
    st.subheader('ğŸ€Step2. è©•ä¾¡å¯¾è±¡ã®è¨­å®š')
    number_of_urls = st.selectbox('URLã®æ•°ã‚’é¸æŠã—ã¦ãã ã•ã„', range(1, 6), format_func=lambda x: f"{x} å€‹")
    # é¸æŠã—ãŸæ•°ã ã‘ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ›æ¬„ã‚’è¡¨ç¤º
    urls = []
    for i in range(number_of_urls):
        url = st.text_input(f"URL {i+1}", key=f"url_{i}")
        if url:  # URLãŒå…¥åŠ›ã•ã‚Œã¦ã„ã‚‹å ´åˆã®ã¿ãƒªã‚¹ãƒˆã«è¿½åŠ 
            urls.append(url)
    st.divider()
    st.subheader('ğŸ€Step3. å˜èªå‡ºç¾å›æ•°ã‚«ã‚¦ãƒ³ãƒˆ')
    all_texts = []
    # ç©ºã§ãªã„URLã®ã¿ã‚’å‡¦ç†
    valid_urls = [url for url in urls if url.strip()]
    for url in valid_urls:
        try:
            text = extract_text_from_url(url)
            all_texts.append(text)
        except requests.exceptions.RequestException as e:
            st.error(f"URL '{url}' ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ã‚¨ãƒ©ãƒ¼: {e}")

    if st.button("ğŸš€å˜èªå‡ºç¾å›æ•°ã‚«ã‚¦ãƒ³ãƒˆå‡¦ç†ã‚’å®Ÿè¡ŒğŸš€"):
        # URLãƒªã‚¹ãƒˆã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã«ä¿å­˜
        st.session_state.urls = urls
        all_texts = [extract_text_from_url(url) for url in urls if url.strip()]
        your_urls_processing_function(df, all_texts, urls)

def your_pdf_processing_function(df, uploaded_file, text, uploaded_file_name):
    # ã“ã“ã§uploaded_fileã‚’ä½¿ç”¨ã™ã‚‹å¿…è¦ãŒã‚ã‚‹å‡¦ç†ã‚’è¨˜è¿°
    if uploaded_file is not None:
        # PDFã®èª­ã¿è¾¼ã¿æˆåŠŸãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ç­‰
        st.success('PDFã®èª­ã¿è¾¼ã¿ã«æˆåŠŸã—ã¾ã—ãŸï¼Step3ã«é€²ã¿ã¾ã™')
        text = extract_text(uploaded_file)
        uploaded_file_name = uploaded_file.name  # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸPDFãƒ•ã‚¡ã‚¤ãƒ«ã®åå‰ã‚’å–å¾—
    else:
        uploaded_file_name = ""
    
    st.caption('PDFç­‰ã®èª­ã¿è¾¼ã¿ã«æ™‚é–“ã‚’è¦ã—ã¾ã™ã€‚')
    st.caption('ä¸‹è¨˜ãƒœã‚¿ãƒ³ã€Œã‚«ã‚¦ãƒ³ãƒˆã€ã‚’æŠ¼ã™ã¾ã§ã«5~10ç§’ã»ã©ãŠå¾…ã¡ã„ãŸã ãã“ã¨ãŒã”ã–ã„ã¾ã™ã€‚')

    st.divider()
    st.subheader('ğŸ€Step3. å˜èªå‡ºç¾å›æ•°ã‚«ã‚¦ãƒ³ãƒˆ')
    if st.button("ğŸš€å˜èªå‡ºç¾å›æ•°ã‚«ã‚¦ãƒ³ãƒˆå‡¦ç†ã‚’å®Ÿè¡ŒğŸš€"):
        keywords = df['åˆ†é¡4'].unique()
        with st.spinner('å‡¦ç†ä¸­...'):

            # å„åˆ†é¡4ã®å˜èªã®å‡ºç¾å›æ•°ã‚’é›†è¨ˆ
            df['å˜èªå‡ºç¾å›æ•°'] = df['åˆ†é¡4'].apply(lambda x: text.lower().count(x.lower()))
            
            # åˆ†é¡3ã”ã¨ã®å˜èªå‡ºç¾å›æ•°ã®åˆè¨ˆã‚’è¨ˆç®—
            df_grouped = df.groupby('åˆ†é¡3').agg({'å˜èªå‡ºç¾å›æ•°': 'sum'}).reset_index().rename(columns={'count': 'count_category3'})
            
            # åˆ†é¡3ã”ã¨ã®åˆè¨ˆã«åŸºã¥ã„ã¦æ–°ã—ã„æ®µéšï¼ˆnew_stageï¼‰ã‚’è¨ˆç®—
            df_grouped['æ®µéš'] = df_grouped['å˜èªå‡ºç¾å›æ•°'].apply(lambda x: x // 10 + 1 if x > 0 else 0)
            
            # æ–°ã—ã„æ®µéšã‚’å…ƒã®DataFrameã«çµåˆ
            df_final = pd.merge(df, df_grouped[['åˆ†é¡3', 'æ®µéš']], on='åˆ†é¡3', how='left')

            display_final_dataframe(df_final)
            download_buttons(df_final, uploaded_file_name)

def your_urls_processing_function(df, all_texts, urls):
    all_counts = []
    # å„URLã«å¯¾ã—ã¦å‡¦ç†ã‚’å®Ÿè¡Œ
    for i, text in enumerate(all_texts):  # URLãƒªã‚¹ãƒˆã®ä»£ã‚ã‚Šã«ãƒ†ã‚­ã‚¹ãƒˆãƒªã‚¹ãƒˆã‚’ä½¿ç”¨
        # URLã”ã¨ã®ã‚«ã‚¦ãƒ³ãƒˆåˆ—å
        count_col_name = f'å˜èªå‡ºç¾å›æ•°_URL_{i+1}'
        # å„ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®å‡ºç¾å›æ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆ
        df[count_col_name] = df['åˆ†é¡4'].apply(lambda x: text.lower().count(x.lower()))
        all_counts.append(count_col_name)
    
    # å„URLã®å˜èªå‡ºç¾å›æ•°ã‚’é›†è¨ˆã—ã¦åˆè¨ˆã‚’è¨ˆç®—
    df['å˜èªå‡ºç¾å›æ•°ï¼ˆåˆè¨ˆï¼‰'] = df[all_counts].sum(axis=1)

    # URLã«å¯¾å¿œã™ã‚‹ãƒ©ãƒ™ãƒ«ã‚’ç”Ÿæˆã—ã€å˜èªå‡ºç¾å›æ•°ï¼ˆå€‹åˆ¥ï¼‰ã®æ–‡å­—åˆ—ã‚’æ›´æ–°
    df['å˜èªå‡ºç¾å›æ•°ï¼ˆå€‹åˆ¥ï¼‰'] = df.apply(lambda x: ', '.join([f"URL {i+1}({x[col]})" for i, col in enumerate(all_counts) if x[col] > 0]), axis=1)
    
    # åˆ†é¡3ã”ã¨ã«å˜èªå‡ºç¾å›æ•°ã®åˆè¨ˆã‚’è¨ˆç®—
    df_grouped = df.groupby('åˆ†é¡3')['å˜èªå‡ºç¾å›æ•°ï¼ˆåˆè¨ˆï¼‰'].sum().reset_index()
    df_grouped.rename(columns={'å˜èªå‡ºç¾å›æ•°ï¼ˆåˆè¨ˆï¼‰': 'count_category3'}, inplace=True)

    # åˆ†é¡3ã”ã¨ã®åˆè¨ˆã«åŸºã¥ã„ã¦æ–°ã—ã„æ®µéšã‚’è¨ˆç®—
    df_grouped['æ®µéš'] = df_grouped['count_category3'].apply(lambda x: max(1, x // 10 + 1) if x > 0 else 0)

    # æ–°ã—ã„æ®µéšã‚’ã‚‚ã¨ã®DataFrameã«çµåˆ
    df_final = pd.merge(df, df_grouped[['åˆ†é¡3', 'æ®µéš']], on='åˆ†é¡3', how='left')

    # çµæœã®è¡¨ç¤ºã¨ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³ã®é…ç½®
    display_final_dataframe(df_final, is_url=True)
    download_buttons(df_final, "evaluation_URLs")

def download_buttons(df, file_name_prefix):
    # ä¸è¦ãªåˆ—ï¼ˆå˜èªå‡ºç¾å›æ•°_URL_xï¼‰ã‚’å‰Šé™¤ã™ã‚‹ãŸã‚ã®å‡¦ç†
    columns_to_remove = [col for col in df.columns if col.startswith('å˜èªå‡ºç¾å›æ•°_URL_')]
    df_cleaned = df.drop(columns=columns_to_remove)

    # CSVãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³
    csv = df_cleaned.to_csv(index=False).encode('utf-8')
    jst = pytz.timezone('Asia/Tokyo')
    now = datetime.now(jst).strftime('%Y%m%d%H%M%S')
    file_name = f"{file_name_prefix}-{now}.csv"
    st.download_button("çµæœã‚’CSVã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", csv, file_name=file_name, mime="text/csv")
    
    # URLãƒªã‚¹ãƒˆãŒå­˜åœ¨ã™ã‚‹å ´åˆ
    if 'urls' in st.session_state and st.session_state.urls and st.session_state.file_type == "Webãƒªãƒ³ã‚¯":
        urls = st.session_state.urls
        url_text = "\n".join([f"URL {i+1}\n{url}" for i, url in enumerate(urls)])
        txt_file_name = f"{file_name_prefix}_{now}.txt"
        st.download_button("URLãƒªã‚¹ãƒˆã‚’TXTãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", url_text.encode('utf-8'), file_name=txt_file_name, mime="text/plain")

def create_txt_download(file_name_prefix, urls):
    # ç¾åœ¨ã®æ—¥æ™‚ã‚’æ—¥æœ¬æ™‚é–“ã§å–å¾—ã—ã€YYYYMMDDHHMMSSå½¢å¼ã§ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
    jst = pytz.timezone('Asia/Tokyo')
    now = datetime.now(jst).strftime('%Y%m%d%H%M%S')
    
    # ãƒ•ã‚¡ã‚¤ãƒ«åã‚’ç”Ÿæˆï¼ˆãƒ•ã‚¡ã‚¤ãƒ«åã®ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ã«ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’å«ã‚€ï¼‰
    txt_file_name = f"{file_name_prefix}_URL_{now}.txt"
    
    # URLãƒ†ã‚­ã‚¹ãƒˆã‚’ç”Ÿæˆï¼ˆå„URLã®å‰ã«ãã®ç•ªå·ã‚’è¡¨ç¤ºï¼‰
    url_text = "\n".join([f"URL {i+1}\n{url}" for i, url in enumerate(urls)])
    
    # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³ã‚’é…ç½®
    st.download_button(
        label="URLãƒªã‚¹ãƒˆã‚’TXTãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
        data=url_text.encode('utf-8'),
        file_name=txt_file_name,
        mime="text/plain",
    )

def display_final_dataframe(df_final, is_url=False):
    # é›†è¨ˆæ–¹æ³•ã®èª¬æ˜
    st.markdown("#### ğŸ§®æ®µéšã®é›†è¨ˆæ–¹æ³•ã®èª¬æ˜")
    st.text("éšå±¤ã¯ã€åˆ†é¡3ã”ã¨ã«é›†è¨ˆã—ã¦ã„ã¾ã™ã€‚")
    st.text("åˆ†é¡3ã”ã¨ã«ã€å„å˜èªï¼ˆåˆ†é¡4ï¼‰ã®å‡ºç¾å›æ•°ã®åˆè¨ˆå€¤ã€ŒMã€ã‚’æ±‚ã‚ã€ä¸‹è¨˜ã§éšå±¤ã®å€¤ã‚’ç®—å‡ºã—ã¦ã„ã¾ã™ã€‚")
    code = """
            éšå±¤ = M Ã· 10 + 1
            ï¼ˆãŸã ã—ã€M = 0ã®å ´åˆã€éšå±¤=0ï¼‰
            """
    st.code(code, language='python')

    # æœ€çµ‚çš„ãªãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’è¡¨ç¤º
    st.markdown("#### ğŸ“Šé›†è¨ˆè¡¨")
    if is_url:
        # URLãƒªã‚¹ãƒˆãŒã‚ã‚‹å ´åˆã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ è¡¨ç¤º
        st.dataframe(df_final[['åˆ†é¡1', 'åˆ†é¡2', 'åˆ†é¡3', 'åˆ†é¡4', 'å˜èªå‡ºç¾å›æ•°ï¼ˆåˆè¨ˆï¼‰', 'æ®µéš', 'å˜èªå‡ºç¾å›æ•°ï¼ˆå€‹åˆ¥ï¼‰']].style.bar(subset=['å˜èªå‡ºç¾å›æ•°ï¼ˆåˆè¨ˆï¼‰'], color='#5fba7d'))
    else:
        # PDFãƒ•ã‚¡ã‚¤ãƒ«ã®å ´åˆã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ è¡¨ç¤º
        st.dataframe(df_final[['åˆ†é¡1', 'åˆ†é¡2', 'åˆ†é¡3', 'åˆ†é¡4', 'å˜èªå‡ºç¾å›æ•°', 'æ®µéš']].style.bar(subset=['å˜èªå‡ºç¾å›æ•°'], color='#5fba7d'))

    # å‡¦ç†å®Œäº†ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
    st.success('å‡¦ç†å®Œäº†ï¼')

if __name__ == "__main__":
    app()
